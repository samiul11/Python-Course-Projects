{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import email,re, nltk,os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "wordlists = set(nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('data/train/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path= 'data/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocess(file_path):\n",
    "    print(file_path)\n",
    "    email_body,reciever = \"\",\"\"\n",
    "    \n",
    "    emails = email.message_from_string(open(file_path, encoding = 'ISO-8859-1').read())\n",
    "    \n",
    "    reciever=emails['To']\n",
    "    # Get E-mail body\n",
    "    if emails.is_multipart():\n",
    "        for payload in emails.get_payload():\n",
    "            # if payload.is_multipart() then.. \n",
    "            email_body = payload.get_payload()\n",
    "    else:\n",
    "        email_body = emails.get_payload()\n",
    "    \n",
    "    # If body has no value\n",
    "    if type(email_body) is not str:\n",
    "        # If body has no value then make it an empty string\n",
    "        if not email_body:\n",
    "            email_body = \"\"\n",
    "        # If body was multipart then the payload will be \n",
    "        # returned as an array with the first index as \n",
    "        # the actual message in the mail\n",
    "        elif type(email_body) is list:\n",
    "            email_body = email_body[0].as_string()\n",
    "    \n",
    "    if type(reciever) is not str:\n",
    "        # If body has no value then make it an empty string\n",
    "        if not reciever:\n",
    "            reciever = \"\"\n",
    "    # Remove numbers and all special characters except space\n",
    "    email_body = re.sub(r'[^a-zA-Z]', ' ', email_body).lower()\n",
    "    reciever = re.sub(r'[^a-zA-Z]', ' ', reciever).lower()\n",
    "    \n",
    "    #Remove foreign words\n",
    "    email_body = \" \".join(w for w in nltk.wordpunct_tokenize(email_body) if w.lower() in wordlists or not w.isalpha())\n",
    "    \n",
    "    # Remove single letter words like 'b', 'j', etc..\n",
    "    email_cleaned = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", email_body)\n",
    "    reciever = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", reciever)\n",
    "    clear_output()\n",
    "    return (email_cleaned,reciever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = dataset.apply(lambda row: Preprocess(main_path+row['Id']), axis=1).apply(pd.Series)\n",
    "dataset['email'],dataset['email_recipients']=dat[0],dat[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(dataset, dataset[['Label']], test_size=0.20, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train( X_train, y_train,word_percentage):\n",
    "    frequent_spam_words = None\n",
    "    frequent_ham_words = None\n",
    "    \n",
    "       \n",
    "    # Get all words in spam and ham emails\n",
    "    spam_words = X_train['email'][y_train['Label'] == 'spam'].str.cat().split()\n",
    "    ham_words = X_train['email'][y_train['Label'] == 'ham'].str.cat().split()\n",
    "    \n",
    "    length_recipients=X_train['email_recipients'].str.len()\n",
    "    uniq_words = len(set(X_train['email'].str.cat().split()))\n",
    "\n",
    "    # % of the most frequent spam and words\n",
    "    frequent_spam_words = Counter(spam_words).most_common(round(uniq_words*(word_percentage/100)))\n",
    "    frequent_spam_words = [w[0] for w in frequent_spam_words]\n",
    "        \n",
    "    frequent_ham_words = Counter(ham_words).most_common(round(uniq_words*(word_percentage/100)))\n",
    "    frequent_ham_words = [w[0] for w in frequent_ham_words]\n",
    "        \n",
    "    return (frequent_spam_words,frequent_ham_words,length_recipients)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    " def predict( X_vals,spam_words,ham_words,recipients):\n",
    "    prediction = []\n",
    "        \n",
    "            \n",
    "    size = X_vals.shape[0]\n",
    "    s = 0\n",
    "    for mail,reciever in zip(X_vals.email,recipients):\n",
    "        spam_count = 0\n",
    "        ham_count = 0\n",
    "        length_reciever=len(str(reciever))       \n",
    "        unique_words_in_email = set(mail.split())\n",
    "                \n",
    "        # Calculate number of spam and ham matches with test set words\n",
    "        for word in unique_words_in_email:\n",
    "            spam_count += 1 if word in spam_words else 0\n",
    "            ham_count += 1 if word in ham_words else 0\n",
    "                \n",
    "        # If there are more spam matches than ham, then predict as spam, otherwise predict as ham.\n",
    "        #if reciever length is less than 40 then add as spam or else ham\n",
    "        if(spam_count > ham_count) and length_reciever <40:\n",
    "            prediction.append('spam')\n",
    "        else:\n",
    "            prediction.append('ham')\n",
    "                \n",
    "        clear_output()\n",
    "        s += 1\n",
    "        print(str(s)+\" out of \"+str(size)+\"(\"+str(100*s/size)+\"%)\")\n",
    "                \n",
    "      \n",
    "        \n",
    "    return prediction        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=train(X_train, y_train,word_percentage=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16582 out of 16582(100.0%)\n"
     ]
    }
   ],
   "source": [
    "predictions = predict(X_validation,words[0],words[1],words[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8073814980098902\n",
      "Precision (Macro | Micro): 0.8290914465734385  |  0.8073814980098902\n",
      "False Positive Rate (FPR): 0.30538922155688625  |  0.040634291377601585\n"
     ]
    }
   ],
   "source": [
    "cnf_matrix = confusion_matrix(y_validation, predictions)\n",
    "\n",
    "FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)  \n",
    "FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "TP = np.diag(cnf_matrix)\n",
    "TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "FPR = FP/(FP+TN)\n",
    "\n",
    "print(\"Accuracy Score:\", accuracy_score(y_validation, predictions))\n",
    "print(\"Precision (Macro | Micro):\", precision_score(y_validation, predictions, average='macro'), \" | \", precision_score(y_validation, predictions, average='micro'))\n",
    "print(\"False Positive Rate (FPR):\", FPR[0], \" | \", FPR[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test paths\n",
    "path = main_path + 'test'\n",
    "file_paths = pd.Series(['test/' + filename + '/' + fname for filename in os.listdir(path) for fname in os.listdir(main_path + 'test/' + filename)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi tonight we are rolling out  new report curr...</td>\n",
       "      <td>lambie  chris   chris lambie enron com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mark  am working with the east power desk to p...</td>\n",
       "      <td>taylor  mark   legal    mark taylor enron com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mark and is ready to bill us for the oil but t...</td>\n",
       "      <td>weldon    charles    charles weldon enron com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>per eric moon attached you will find the slide...</td>\n",
       "      <td>garberding  michael   michael garberding enro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>return path from full name message id     date...</td>\n",
       "      <td>baughman jr   don   don baughman enron com   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  hi tonight we are rolling out  new report curr...   \n",
       "1  mark  am working with the east power desk to p...   \n",
       "2  mark and is ready to bill us for the oil but t...   \n",
       "3  per eric moon attached you will find the slide...   \n",
       "4  return path from full name message id     date...   \n",
       "\n",
       "                                                   1  \n",
       "0            lambie  chris   chris lambie enron com   \n",
       "1     taylor  mark   legal    mark taylor enron com   \n",
       "2   weldon    charles    charles weldon enron com...  \n",
       "3   garberding  michael   michael garberding enro...  \n",
       "4   baughman jr   don   don baughman enron com   ...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test emails using paths\n",
    "test_data = file_paths.apply(lambda row: Preprocess(main_path + row)).apply(pd.Series)\n",
    "test_data.columns = ['email', 'email_recipients']\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with all data\n",
    "total_train=train(dataset, dataset[['Label']],word_percentage=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9283 out of 9283(100.0%)\n"
     ]
    }
   ],
   "source": [
    "# Predictions for Test Data\n",
    "predictions = predict(test_data,total_train[0],total_train[1],total_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the submission file for Kaggle\n",
    "submission = pd.DataFrame({\n",
    "    'Id': file_paths,\n",
    "    'Label': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
