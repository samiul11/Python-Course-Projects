{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import email,nltk,re,os,numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.PorterStemmer()\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "wordlists = set(nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('data/train/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path= 'data/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocess(file_path):\n",
    "    print(file_path)\n",
    "   \n",
    "    \n",
    "    emails = email.message_from_string(open(file_path, encoding = 'ISO-8859-1').read())\n",
    "    email_subject=emails['Subject']\n",
    "    \n",
    "    # Get E-mail body\n",
    "    if emails.is_multipart():\n",
    "        for payload in emails.get_payload():\n",
    "            # if payload.is_multipart() then.. \n",
    "            email_body = payload.get_payload()\n",
    "    else:\n",
    "        email_body = emails.get_payload()\n",
    "    \n",
    "    # If body has no value\n",
    "    if type(email_body) is not str:\n",
    "        # If body has no value then make it an empty string\n",
    "        if not email_body:\n",
    "            email_body = \"\"\n",
    "        # If body was multipart then the payload will be \n",
    "        # returned as an array with the first index as \n",
    "        # the actual message in the mail\n",
    "        elif type(email_body) is list:\n",
    "            email_body = email_body[0].as_string()\n",
    "            \n",
    "    if type(email_subject) is not str:\n",
    "        # If body has no value then make it an empty string\n",
    "        if not email_subject:\n",
    "            email_subject = \"\"\n",
    "    #count number of special characters\n",
    "    email_subject_count = len(email_subject) - len( re.findall('[\\w]', email_subject) )\n",
    "    \n",
    "    # Remove numbers and all special characters except space\n",
    "    email_body = re.sub(r'[^a-zA-Z]', ' ', email_body).lower()\n",
    "    \n",
    "    #Remove foreign words\n",
    "    email_body = \" \".join(w for w in nltk.wordpunct_tokenize(email_body) if w.lower() in wordlists or not w.isalpha())\n",
    "    \n",
    "    email_ = [word for word in email_body.split() if word not in stopwords]\n",
    "    email_stemmed = \" \".join([stemmer.stem(word) for word in email_])\n",
    "    # Remove single letter words like 'b', 'j', etc..\n",
    "    email_cleaned = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", email_body)\n",
    "    email_body_cleaned = \" \".join(email_cleaned.split())\n",
    "    \n",
    "    email_body_lenth=len(email_body_cleaned)\n",
    "    \n",
    "    email_return_path=emails['Return-Path']\n",
    "    if email_return_path == None:\n",
    "        email_return_path=1\n",
    "    else:\n",
    "        email_return_path=0\n",
    "    clear_output()\n",
    "    return (email_cleaned,email_return_path,email_subject_count,email_body_lenth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = dataset.apply(lambda row: Preprocess(main_path+row['Id']), axis=1).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['email'],dataset['email_return_path'],dataset['email_subject_count'],dataset['email_body_lenth']=dat[0],dat[1],dat[2],dat[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['email'] = dataset['email'].replace(np.nan, '', regex=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Label</th>\n",
       "      <th>email</th>\n",
       "      <th>email_return_path</th>\n",
       "      <th>email_subject_count</th>\n",
       "      <th>email_body_lenth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/000/000</td>\n",
       "      <td>ham</td>\n",
       "      <td>user id original message from sent june to sub...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>9069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/000/002</td>\n",
       "      <td>ham</td>\n",
       "      <td>these new original message from  sent june am...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/000/003</td>\n",
       "      <td>ham</td>\n",
       "      <td>we are currently trading under spot with el fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/000/004</td>\n",
       "      <td>ham</td>\n",
       "      <td>and attached is  for  new master physical with...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/000/005</td>\n",
       "      <td>ham</td>\n",
       "      <td>below is  copy of my communication with regard...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id Label                                              email  \\\n",
       "0  train/000/000   ham  user id original message from sent june to sub...   \n",
       "1  train/000/002   ham   these new original message from  sent june am...   \n",
       "2  train/000/003   ham  we are currently trading under spot with el fo...   \n",
       "3  train/000/004   ham  and attached is  for  new master physical with...   \n",
       "4  train/000/005   ham  below is  copy of my communication with regard...   \n",
       "\n",
       "   email_return_path  email_subject_count  email_body_lenth  \n",
       "0                  0                   13              9069  \n",
       "1                  0                    3               343  \n",
       "2                  0                    5               914  \n",
       "3                  0                    2               228  \n",
       "4                  0                    6               698  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Validation Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(dataset, dataset['Label'], test_size=0.20, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Vectorizer vocabulary\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(dataset['email'])\n",
    "\n",
    "# len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectors\n",
    "X_train_vector = vectorizer.transform(X_train['email'])\n",
    "X_val_vector = vectorizer.transform(X_val['email'])\n",
    "\n",
    "# print(X_train_vec.shape, X_val_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF Vector\n",
    "tf_transformer = TfidfTransformer(norm='l1', use_idf=False)\n",
    "\n",
    "X_train_vector_tf = tf_transformer.fit_transform(X_train_vector)\n",
    "X_val_vector_tf = tf_transformer.fit_transform(X_val_vector)\n",
    "\n",
    "# print(X_train_vec_tf.shape, X_val_vec_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vector\n",
    "tfidf_transformer = TfidfTransformer(norm='l1', use_idf=True)\n",
    "\n",
    "X_train_vector_tfidf = tfidf_transformer.fit_transform(X_train_vector)\n",
    "X_val_vector_tfidf = tfidf_transformer.fit_transform(X_val_vector)\n",
    "\n",
    "# print(X_train_vec_tfidf.shape, X_val_vec_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify with train,validation data-Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive-Bayes with Count\n",
      "Accuracy Score: 0.8671450970932336\n",
      "Precision: 0.9287388654477262\n",
      "False Positive Rate (FPR): 0.08608240124592949\n"
     ]
    }
   ],
   "source": [
    "# Naive-Bayes Classifier\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "# Naive-Bayes with Count\n",
    "classifier.fit(X_train_vector, y_train)\n",
    "predictions = classifier.predict(X_val_vector)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "Accuracy=(tp + tn) / (tp + tn + fp + fn)\n",
    "Precision=(tp / (tp + fp))\n",
    "FPR=(fp / (fp + tn))\n",
    "\n",
    "print('Naive-Bayes with Count')\n",
    "print(\"Accuracy Score:\",Accuracy)\n",
    "print(\"Precision:\",Precision)\n",
    "print(\"False Positive Rate (FPR):\",FPR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive-Bayes with TF\n",
      "Accuracy Score: 0.8900012061271259\n",
      "Precision: 0.8433122155795485\n",
      "False Positive Rate (FPR): 0.24861956675633584\n"
     ]
    }
   ],
   "source": [
    "# Naive-Bayes with Term Frequency\n",
    "classifier.fit(X_train_vector_tf, y_train)\n",
    "predictions = classifier.predict(X_val_vector_tf)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "Accuracy=(tp + tn) / (tp + tn + fp + fn)\n",
    "Precision=(tp / (tp + fp))\n",
    "FPR=(fp / (fp + tn))\n",
    "\n",
    "print('Naive-Bayes with TF')\n",
    "print(\"Accuracy Score:\",Accuracy)\n",
    "print(\"Precision:\",Precision)\n",
    "print(\"False Positive Rate (FPR):\",FPR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive-Bayes with TF-IDF\n",
      "Accuracy Score: 0.907610662163792\n",
      "Precision: 0.8666115854218306\n",
      "False Positive Rate (FPR): 0.20571994903015717\n"
     ]
    }
   ],
   "source": [
    "# Naive-Bayes with Term Frequency-Inverse Document Frequency\n",
    "classifier.fit(X_train_vector_tfidf, y_train)\n",
    "predictions = classifier.predict(X_val_vector_tfidf)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "Accuracy=(tp + tn) / (tp + tn + fp + fn)\n",
    "Precision=(tp / (tp + fp))\n",
    "FPR=(fp / (fp + tn))\n",
    "\n",
    "print('Naive-Bayes with TF-IDF')\n",
    "print(\"Accuracy Score:\",Accuracy)\n",
    "print(\"Precision:\",Precision)\n",
    "print(\"False Positive Rate (FPR):\",FPR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify with train,validation data-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with Count\n",
      "Accuracy Score: 0.9542877819322156\n",
      "Precision: 0.9430565388894508\n",
      "False Positive Rate (FPR): 0.07971117089055642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samiul\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine Classifier\n",
    "classifier = LinearSVC(random_state = 0)\n",
    "\n",
    "# SVM with Count\n",
    "classifier.fit(X_train_vector, y_train)\n",
    "predictions = classifier.predict(X_val_vector)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "\n",
    "Accuracy=(tp + tn) / (tp + tn + fp + fn)\n",
    "Precision=(tp / (tp + fp))\n",
    "FPR=(fp / (fp + tn))\n",
    "\n",
    "print('SVM with Count')\n",
    "print(\"Accuracy Score:\",Accuracy)\n",
    "print(\"Precision:\",Precision)\n",
    "print(\"False Positive Rate (FPR):\",FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with TF\n",
      "Accuracy Score: 0.9419852852490652\n",
      "Precision: 0.9565681357379149\n",
      "False Positive Rate (FPR): 0.057624238991929776\n"
     ]
    }
   ],
   "source": [
    "# SVM with Term Frequency\n",
    "classifier.fit(X_train_vector_tf, y_train)\n",
    "predictions = classifier.predict(X_val_vector_tf)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "\n",
    "Accuracy=(tp + tn) / (tp + tn + fp + fn)\n",
    "Precision=(tp / (tp + fp))\n",
    "FPR=(fp / (fp + tn))\n",
    "\n",
    "print('SVM with TF')\n",
    "print(\"Accuracy Score:\",Accuracy)\n",
    "print(\"Precision:\",Precision)\n",
    "print(\"False Positive Rate (FPR):\",FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with TF-IDF\n",
      "Accuracy Score: 0.9476540827403208\n",
      "Precision: 0.9344179973887717\n",
      "False Positive Rate (FPR): 0.09245363160130256\n"
     ]
    }
   ],
   "source": [
    "# SVM with Term Frequency-Inverse Document Frequency\n",
    "classifier.fit(X_train_vector_tfidf, y_train)\n",
    "predictions = classifier.predict(X_val_vector_tfidf)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "\n",
    "Accuracy=(tp + tn) / (tp + tn + fp + fn)\n",
    "Precision=(tp / (tp + fp))\n",
    "FPR=(fp / (fp + tn))\n",
    "\n",
    "print('SVM with TF-IDF')\n",
    "print(\"Accuracy Score:\",Accuracy)\n",
    "print(\"Precision:\",Precision)\n",
    "print(\"False Positive Rate (FPR):\",FPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorizer with new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(dataset['email'])\n",
    "# len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vec = vectorizer.transform(dataset['email'])\n",
    "# data_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With 1 Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vec1=hstack((data_vec,dataset[['email_return_path']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Validation Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(data_vec1, dataset['Label'], test_size=0.20, random_state = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive-Bayes with feature1\n",
      "Accuracy Score: 0.8979616451573996\n",
      "Precision: 0.9327656751078182\n",
      "False Positive Rate (FPR): 0.08608240124592949\n"
     ]
    }
   ],
   "source": [
    "# Naive-Bayes\n",
    "classifier = MultinomialNB().fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_val)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "\n",
    "Accuracy=(tp + tn) / (tp + tn + fp + fn)\n",
    "Precision=(tp / (tp + fp))\n",
    "FPR=(fp / (fp + tn))\n",
    "\n",
    "print('Naive-Bayes with feature1')\n",
    "print(\"Accuracy Score:\",Accuracy)\n",
    "print(\"Precision:\",Precision)\n",
    "print(\"False Positive Rate (FPR):\",FPR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with feature1\n",
      "Accuracy Score: 0.9876371969605596\n",
      "Precision: 0.9899011150852094\n",
      "False Positive Rate (FPR): 0.01359195809146255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samiul\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM\n",
    "classifier = LinearSVC(random_state = 0).fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_val)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "\n",
    "Accuracy=(tp + tn) / (tp + tn + fp + fn)\n",
    "Precision=(tp / (tp + fp))\n",
    "FPR=(fp / (fp + tn))\n",
    "\n",
    "print('SVM with feature1')\n",
    "print(\"Accuracy Score:\",Accuracy)\n",
    "print(\"Precision:\",Precision)\n",
    "print(\"False Positive Rate (FPR):\",FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree with feature1\n",
      "Accuracy Score: 0.9887227113737788\n",
      "Precision: 0.9892010903753408\n",
      "False Positive Rate (FPR): 0.014583038368965028\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "classifier = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_val)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "\n",
    "Accuracy=(tp + tn) / (tp + tn + fp + fn)\n",
    "Precision=(tp / (tp + fp))\n",
    "FPR=(fp / (fp + tn))\n",
    "\n",
    "print('Decision Tree with feature1')\n",
    "print(\"Accuracy Score:\",Accuracy)\n",
    "print(\"Precision:\",Precision)\n",
    "print(\"False Positive Rate (FPR):\",FPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With feature 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vec2=hstack((data_vec,dataset[['email_subject_count']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Validation Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(data_vec2, dataset['Label'], test_size=0.20, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive-Bayes with feature2\n",
      "Accuracy Score: 0.8808346399710529\n",
      "Precision: 0.9041037179899282\n",
      "False Positive Rate (FPR): 0.12671669262353108\n"
     ]
    }
   ],
   "source": [
    "# Naive-Bayes\n",
    "classifier = MultinomialNB().fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_val)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "\n",
    "Accuracy=(tp + tn) / (tp + tn + fp + fn)\n",
    "Precision=(tp / (tp + fp))\n",
    "FPR=(fp / (fp + tn))\n",
    "\n",
    "print('Naive-Bayes with feature2')\n",
    "print(\"Accuracy Score:\",Accuracy)\n",
    "print(\"Precision:\",Precision)\n",
    "print(\"False Positive Rate (FPR):\",FPR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with feature2\n",
      "Accuracy Score: 0.9617054637558798\n",
      "Precision: 0.9655208551666318\n",
      "False Positive Rate (FPR): 0.04658077304261645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samiul\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM\n",
    "classifier = LinearSVC(random_state = 0).fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_val)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "\n",
    "Accuracy=(tp + tn) / (tp + tn + fp + fn)\n",
    "Precision=(tp / (tp + fp))\n",
    "FPR=(fp / (fp + tn))\n",
    "\n",
    "print('SVM with feature2')\n",
    "print(\"Accuracy Score:\",Accuracy)\n",
    "print(\"Precision:\",Precision)\n",
    "print(\"False Positive Rate (FPR):\",FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree with feature2\n",
      "Accuracy Score: 0.9457845856953323\n",
      "Precision: 0.947188213322266\n",
      "False Positive Rate (FPR): 0.07206569446410874\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "classifier = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_val)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "\n",
    "Accuracy=(tp + tn) / (tp + tn + fp + fn)\n",
    "Precision=(tp / (tp + fp))\n",
    "FPR=(fp / (fp + tn))\n",
    "\n",
    "print('Decision Tree with feature2')\n",
    "print(\"Accuracy Score:\",Accuracy)\n",
    "print(\"Precision:\",Precision)\n",
    "print(\"False Positive Rate (FPR):\",FPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With feature 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vec3=hstack((data_vec,dataset[['email_body_lenth']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Validation Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(data_vec3, dataset['Label'], test_size=0.20, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive-Bayes with feature3\n",
      "Accuracy Score: 0.8672657098058135\n",
      "Precision: 0.9288560712611346\n",
      "False Positive Rate (FPR): 0.08594081834914342\n"
     ]
    }
   ],
   "source": [
    "# Naive-Bayes\n",
    "classifier = MultinomialNB().fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_val)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "\n",
    "Accuracy=(tp + tn) / (tp + tn + fp + fn)\n",
    "Precision=(tp / (tp + fp))\n",
    "FPR=(fp / (fp + tn))\n",
    "\n",
    "print('Naive-Bayes with feature3')\n",
    "print(\"Accuracy Score:\",Accuracy)\n",
    "print(\"Precision:\",Precision)\n",
    "print(\"False Positive Rate (FPR):\",FPR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with feature3\n",
      "Accuracy Score: 0.9337836207936316\n",
      "Precision: 0.9449434640177533\n",
      "False Positive Rate (FPR): 0.07376468922554155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samiul\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM\n",
    "classifier = LinearSVC(random_state = 0).fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_val)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "\n",
    "Accuracy=(tp + tn) / (tp + tn + fp + fn)\n",
    "Precision=(tp / (tp + fp))\n",
    "FPR=(fp / (fp + tn))\n",
    "\n",
    "print('SVM with feature3')\n",
    "print(\"Accuracy Score:\",Accuracy)\n",
    "print(\"Precision:\",Precision)\n",
    "print(\"False Positive Rate (FPR):\",FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree with feature3\n",
      "Accuracy Score: 0.9429501869497044\n",
      "Precision: 0.956642164695856\n",
      "False Positive Rate (FPR): 0.057624238991929776\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "classifier = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_val)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "\n",
    "Accuracy=(tp + tn) / (tp + tn + fp + fn)\n",
    "Precision=(tp / (tp + fp))\n",
    "FPR=(fp / (fp + tn))\n",
    "\n",
    "print('Decision Tree with feature3')\n",
    "print(\"Accuracy Score:\",Accuracy)\n",
    "print(\"Precision:\",Precision)\n",
    "print(\"False Positive Rate (FPR):\",FPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With all Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vec_full=hstack((data_vec,dataset[['email_subject_count','email_body_lenth','email_return_path']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Validation Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(data_vec_full, dataset['Label'], test_size=0.20, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive-Bayes with all feature\n",
      "Accuracy Score: 0.8968761307441805\n",
      "Precision: 0.9070155321588659\n",
      "False Positive Rate (FPR): 0.12629194393317286\n"
     ]
    }
   ],
   "source": [
    "# Naive-Bayes\n",
    "classifier = MultinomialNB().fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_val)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "\n",
    "Accuracy=(tp + tn) / (tp + tn + fp + fn)\n",
    "Precision=(tp / (tp + fp))\n",
    "FPR=(fp / (fp + tn))\n",
    "\n",
    "print('Naive-Bayes with all feature')\n",
    "print(\"Accuracy Score:\",Accuracy)\n",
    "print(\"Precision:\",Precision)\n",
    "print(\"False Positive Rate (FPR):\",FPR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with all feature\n",
      "Accuracy Score: 0.9334820890121819\n",
      "Precision: 0.9917036690815612\n",
      "False Positive Rate (FPR): 0.010052385671810845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samiul\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM\n",
    "classifier = LinearSVC(random_state = 0).fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_val)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "\n",
    "Accuracy=(tp + tn) / (tp + tn + fp + fn)\n",
    "Precision=(tp / (tp + fp))\n",
    "FPR=(fp / (fp + tn))\n",
    "\n",
    "print('SVM with all feature')\n",
    "print(\"Accuracy Score:\",Accuracy)\n",
    "print(\"Precision:\",Precision)\n",
    "print(\"False Positive Rate (FPR):\",FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree with all feature\n",
      "Accuracy Score: 0.9881799541671692\n",
      "Precision: 0.9891908909644244\n",
      "False Positive Rate (FPR): 0.014583038368965028\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "classifier = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_val)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_val, predictions).ravel()\n",
    "\n",
    "Accuracy=(tp + tn) / (tp + tn + fp + fn)\n",
    "Precision=(tp / (tp + fp))\n",
    "FPR=(fp / (fp + tn))\n",
    "\n",
    "print('Decision Tree with all feature')\n",
    "print(\"Accuracy Score:\",Accuracy)\n",
    "print(\"Precision:\",Precision)\n",
    "print(\"False Positive Rate (FPR):\",FPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train SVM with full train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVM\n",
    "classifier = LinearSVC(random_state = 0).fit(data_vec_full, dataset['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test paths\n",
    "path = main_path + 'test'\n",
    "file_paths = pd.Series(['test/' + filename + '/' + fname for filename in os.listdir(path) for fname in os.listdir(main_path + 'test/' + filename)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test emails using paths\n",
    "test_data = file_paths.apply(lambda row: Preprocess(main_path + row)).apply(pd.Series)\n",
    "test_data.columns = ['email', 'email_return_path','email_subject_count','email_body_lenth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>email_return_path</th>\n",
       "      <th>email_subject_count</th>\n",
       "      <th>email_body_lenth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi tonight we are rolling out  new report curr...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mark  am working with the east power desk to p...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mark and is ready to bill us for the oil but t...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>per eric moon attached you will find the slide...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>return path from full name message id     date...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               email  email_return_path  \\\n",
       "0  hi tonight we are rolling out  new report curr...                  0   \n",
       "1  mark  am working with the east power desk to p...                  0   \n",
       "2  mark and is ready to bill us for the oil but t...                  0   \n",
       "3  per eric moon attached you will find the slide...                  0   \n",
       "4  return path from full name message id     date...                  1   \n",
       "\n",
       "   email_subject_count  email_body_lenth  \n",
       "0                    3               409  \n",
       "1                    2               372  \n",
       "2                    2               354  \n",
       "3                    0                72  \n",
       "4                   11              1902  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['email'] = test_data['email'].replace(np.nan, '', regex=True) \n",
    "\n",
    "test_data_vector = vectorizer.transform(test_data['email'])\n",
    "\n",
    "test_data_vector_full = hstack((test_data_vector, test_data[['email_return_path','email_subject_count','email_body_lenth']].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Label'] = classifier.predict(test_data_vector_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'Id': file_paths,\n",
    "    'Label': test_data['Label']\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
