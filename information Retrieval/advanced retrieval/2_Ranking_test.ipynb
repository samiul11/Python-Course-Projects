{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2B: Ranking\n",
    "\n",
    "This notebook contains the skeleton for training a model and then applying it to produce a document ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the precomputed features\n",
    "\n",
    "The code below loads the precomputed features and combines them into feature vectors for query-document pairs.\n",
    "\n",
    "For this part to work, you'll need to run the `1_Feature_computation` notebook first to generate the sample features JSON files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERIES_FILE = \"data/queries.txt\"\n",
    "QRELS_FILE = \"data/qrels.csv\"\n",
    "QUERY2_FILE ='data/queries2.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_queries(query_file):\n",
    "    queries = {}\n",
    "    with open(query_file, \"r\") as fin:\n",
    "        for line in fin.readlines():\n",
    "            qid, query = line.strip().split(\" \", 1)\n",
    "            queries[qid] = query\n",
    "    return queries\n",
    "queries = load_queries(QUERIES_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_qrels(qrels_file):\n",
    "    labels = {}\n",
    "    with open(qrels_file, \"r\") as fin:\n",
    "        for line in fin.readlines()[1:]:\n",
    "            qid, docID, relevance = line.strip().split(\",\")\n",
    "            label = qid+\"-\"+docID\n",
    "            labels[label] = int(relevance)\n",
    "\n",
    "    return labels\n",
    "\n",
    "qrels = load_qrels(QRELS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(queries, features_to_load):\n",
    "    feature_names = []\n",
    "    features = {}\n",
    "    for f in features_to_load:\n",
    "        print(\"Loading features from {}\".format(f['file']))\n",
    "        feature_names += f['features']\n",
    "        with open(f['file']) as json_file:\n",
    "            data = json.load(json_file)\n",
    "            \n",
    "            for q, qdocs in data.items():\n",
    "                for d, feature_values in qdocs.items():\n",
    "                    key = \"{}-{}\".format(q, d)\n",
    "                    for feature_name in f['features']:\n",
    "                        # Note: no error checking is performed. It is assumed that all feature files\n",
    "                        # contain the same queries and documents.\n",
    "                        fvect = features.get(key, [])\n",
    "                        fvect.append(feature_values[feature_name])\n",
    "                        features[key] = fvect\n",
    "\n",
    "    print(\"Feature vector: {}\".format(feature_names))\n",
    "    new_feature = {}\n",
    "    for key,value in features.items():\n",
    "        if sum(value[1:]) > 0:\n",
    "            new_feature[key] = value\n",
    "    return new_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features from data/features_1.json\n",
      "Loading features from data/features_2.json\n",
      "Loading features from data/features_4.json\n",
      "Loading features from data/features_5.json\n",
      "Loading features from data/features_6.json\n",
      "Feature vector: ['qlen', 'bm25_title', 'bm25_content', 'idf_title', 'idf_content', 'docLen_title', 'docLen_content', 'docLen_anchor', 'pagerank']\n"
     ]
    }
   ],
   "source": [
    "# Specify the features to be loaded from each file.\n",
    "# They will make up the feature vector in this exact order.\n",
    "features_to_load = [\n",
    "    {\n",
    "        'file': \"data/features_1.json\",\n",
    "        'features': [\"qlen\"]\n",
    "    },\n",
    "    {\n",
    "        'file': \"data/features_2.json\",\n",
    "        'features': [\"bm25_title\", \"bm25_content\"]\n",
    "    },\n",
    "    #{\n",
    "    #    'file': \"data/features_3.json\",\n",
    "    #    'features': [\"mlm\"]\n",
    "    #},\n",
    "    {\n",
    "        'file': \"data/features_4.json\", \n",
    "        'features': [\"idf_title\", \"idf_content\"]\n",
    "    } ,\n",
    "    {\n",
    "        'file': \"data/features_5.json\", \n",
    "        'features': [\"docLen_title\", \"docLen_content\", \"docLen_anchor\"]\n",
    "    },\n",
    "    {\n",
    "        'file': \"data/features_6.json\", \n",
    "        'features': [\"pagerank\"]\n",
    "    } \n",
    "]\n",
    "\n",
    "features = load_features(queries, features_to_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "feat_data=pd.DataFrame.from_dict(features,orient='index',columns=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load for queries2 features and ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, Y, qids, doc_ids=load_train_data(features2,qrels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries2=load_queries(QUERY2_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features from data/queries2/features_1.json\n",
      "Loading features from data/queries2/features_2.json\n",
      "Loading features from data/queries2/features_4.json\n",
      "Loading features from data/queries2/features_5.json\n",
      "Loading features from data/queries2/features_6.json\n",
      "Feature vector: ['qlen', 'bm25_title', 'bm25_content', 'idf_title', 'idf_content', 'docLen_title', 'docLen_content', 'docLen_anchor', 'pagerank']\n"
     ]
    }
   ],
   "source": [
    "features_to_load = [\n",
    "    {\n",
    "        'file': \"data/queries2/features_1.json\",\n",
    "        'features': [\"qlen\"]\n",
    "    },\n",
    "    {\n",
    "        'file': \"data/queries2/features_2.json\",\n",
    "        'features': [\"bm25_title\", \"bm25_content\"]\n",
    "    },\n",
    "    #{\n",
    "    #    'file': \"data/features_3.json\",\n",
    "    #    'features': [\"mlm\"]\n",
    "    #},\n",
    "    {\n",
    "        'file': \"data/queries2/features_4.json\", \n",
    "        'features': [\"idf_title\", \"idf_content\"]\n",
    "    } ,\n",
    "    {\n",
    "        'file': \"data/queries2/features_5.json\", \n",
    "        'features': [\"docLen_title\", \"docLen_content\", \"docLen_anchor\"]\n",
    "    },\n",
    "    {\n",
    "        'file': \"data/queries2/features_6.json\", \n",
    "        'features': [\"pagerank\"]\n",
    "    } \n",
    "]\n",
    "features2 = load_features(queries2, features_to_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model\n",
    "\n",
    "Training needs to be done differently based on the scenario:\n",
    "\n",
    "  * **Scenario 1**: The model is trained using cross-validation, that is on 4/5 of queries, then applied on the remaining 1/5 of queries (repeated 5 times).\n",
    "  * **Scenario 2**: The model is trained on all available training data.\n",
    "  \n",
    "The feature vectors at this point are already created. These should contain both (a) the training queries and (b) the queries on which you want to apply your model.\n",
    "\n",
    "Train your model on queries (a). For that you'll also need to load the corresponding relevance labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### split the data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestRegressor(max_depth=3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scenario-1: train with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>201-clueweb12-0000wb-60-01497</td>\n",
       "      <td>2</td>\n",
       "      <td>31.367764</td>\n",
       "      <td>30.951880</td>\n",
       "      <td>18.170073</td>\n",
       "      <td>11.587501</td>\n",
       "      <td>9</td>\n",
       "      <td>3355</td>\n",
       "      <td>0</td>\n",
       "      <td>5.200236e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201-clueweb12-0106wb-18-19516</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>5258</td>\n",
       "      <td>0</td>\n",
       "      <td>1.707008e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201-clueweb12-0108wb-22-26598</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>9304</td>\n",
       "      <td>0</td>\n",
       "      <td>7.371517e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201-clueweb12-0301tw-21-03835</td>\n",
       "      <td>2</td>\n",
       "      <td>21.564389</td>\n",
       "      <td>63.968048</td>\n",
       "      <td>18.178139</td>\n",
       "      <td>11.580397</td>\n",
       "      <td>14</td>\n",
       "      <td>835</td>\n",
       "      <td>0</td>\n",
       "      <td>2.063839e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201-clueweb12-0307wb-47-02869</td>\n",
       "      <td>2</td>\n",
       "      <td>66.874364</td>\n",
       "      <td>71.499628</td>\n",
       "      <td>18.135870</td>\n",
       "      <td>11.585547</td>\n",
       "      <td>3</td>\n",
       "      <td>611</td>\n",
       "      <td>0</td>\n",
       "      <td>1.835034e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250-clueweb12-1802wb-92-24344</td>\n",
       "      <td>3</td>\n",
       "      <td>18.869161</td>\n",
       "      <td>75.630484</td>\n",
       "      <td>7.059194</td>\n",
       "      <td>10.523420</td>\n",
       "      <td>5</td>\n",
       "      <td>316</td>\n",
       "      <td>0</td>\n",
       "      <td>1.707008e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250-clueweb12-1804wb-22-03257</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.707008e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250-clueweb12-1810wb-24-22652</td>\n",
       "      <td>3</td>\n",
       "      <td>26.850440</td>\n",
       "      <td>34.296282</td>\n",
       "      <td>14.363648</td>\n",
       "      <td>10.504713</td>\n",
       "      <td>8</td>\n",
       "      <td>2424</td>\n",
       "      <td>0</td>\n",
       "      <td>2.016969e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250-clueweb12-1913wb-64-15762</td>\n",
       "      <td>3</td>\n",
       "      <td>38.128630</td>\n",
       "      <td>42.417501</td>\n",
       "      <td>14.345173</td>\n",
       "      <td>7.988730</td>\n",
       "      <td>5</td>\n",
       "      <td>943</td>\n",
       "      <td>0</td>\n",
       "      <td>1.707008e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250-clueweb12-1914wb-04-28610</td>\n",
       "      <td>3</td>\n",
       "      <td>33.672818</td>\n",
       "      <td>40.933248</td>\n",
       "      <td>14.351626</td>\n",
       "      <td>7.991811</td>\n",
       "      <td>6</td>\n",
       "      <td>1011</td>\n",
       "      <td>0</td>\n",
       "      <td>1.707008e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3668 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0          1          2          3          4  \\\n",
       "201-clueweb12-0000wb-60-01497  2  31.367764  30.951880  18.170073  11.587501   \n",
       "201-clueweb12-0106wb-18-19516  2   0.000000   0.000000   0.000000   0.000000   \n",
       "201-clueweb12-0108wb-22-26598  2   0.000000   0.000000   0.000000   0.000000   \n",
       "201-clueweb12-0301tw-21-03835  2  21.564389  63.968048  18.178139  11.580397   \n",
       "201-clueweb12-0307wb-47-02869  2  66.874364  71.499628  18.135870  11.585547   \n",
       "...                           ..        ...        ...        ...        ...   \n",
       "250-clueweb12-1802wb-92-24344  3  18.869161  75.630484   7.059194  10.523420   \n",
       "250-clueweb12-1804wb-22-03257  3   0.000000   0.000000   0.000000   0.000000   \n",
       "250-clueweb12-1810wb-24-22652  3  26.850440  34.296282  14.363648  10.504713   \n",
       "250-clueweb12-1913wb-64-15762  3  38.128630  42.417501  14.345173   7.988730   \n",
       "250-clueweb12-1914wb-04-28610  3  33.672818  40.933248  14.351626   7.991811   \n",
       "\n",
       "                                5     6  7             8  \n",
       "201-clueweb12-0000wb-60-01497   9  3355  0  5.200236e-08  \n",
       "201-clueweb12-0106wb-18-19516  11  5258  0  1.707008e-08  \n",
       "201-clueweb12-0108wb-22-26598   9  9304  0  7.371517e-08  \n",
       "201-clueweb12-0301tw-21-03835  14   835  0  2.063839e-08  \n",
       "201-clueweb12-0307wb-47-02869   3   611  0  1.835034e-08  \n",
       "...                            ..   ... ..           ...  \n",
       "250-clueweb12-1802wb-92-24344   5   316  0  1.707008e-08  \n",
       "250-clueweb12-1804wb-22-03257   0     0  0  1.707008e-08  \n",
       "250-clueweb12-1810wb-24-22652   8  2424  0  2.016969e-08  \n",
       "250-clueweb12-1913wb-64-15762   5   943  0  1.707008e-08  \n",
       "250-clueweb12-1914wb-04-28610   6  1011  0  1.707008e-08  \n",
       "\n",
       "[3668 rows x 9 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "feat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_data.columns = ['0', '1', '2','3','4','5','6','7','8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel=[]\n",
    "for d,v in qrels.items():\n",
    "    if d in feat_data.index.values:\n",
    "        rel.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_data['QueryId'], feat_data['DocumentId'] = feat_data.index.str.split('-', 1).str\n",
    "feat_data.reset_index(inplace=True)\n",
    "feat_data.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_data['target']=rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feat_data[['0','1','2']], feat_data['target'], test_size=0.20, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samiul\\Anaconda86\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                      n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(734,)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3668, 12)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_data2=pd.DataFrame.from_dict(features2,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_data2.columns = ['0', '1', '2','3','4','5','6','7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                      n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(feat_data[['0', '1', '2','3','4','5','6','7','8']], feat_data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_data2['QueryId'], feat_data2['DocumentId'] = feat_data2.index.str.split('-', 1).str\n",
    "feat_data2.reset_index(inplace=True)\n",
    "feat_data2.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 9 and input n_features is 8 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-244-463402c5a0c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions_full\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat_data2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'3'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'4'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'5'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'6'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'7'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda86\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimators_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda86\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    357\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda86\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    400\u001b[0m                              \u001b[1;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 9 and input n_features is 8 "
     ]
    }
   ],
   "source": [
    "predictions_full=clf.predict(feat_data2[['0', '1', '2','3','4','5','6','7']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('data/sample_predict.txt',predictions_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_data2['prediction']=predictions_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_data2=feat_data2.sort_values(by=['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_data2.to_csv('data/myranking.csv',columns=['qid','did'],index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
